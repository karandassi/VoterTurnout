#Shows business travel is somewhat dependent on Gender
tbl <- table(hraReducedBusiness$Gender, hraReducedBusiness$Department)
tbl
chisq.test(tbl)
#Shows that Gender and Department are slightly correlated
tbl <- table(hraReducedBusiness$MaritalStatus, hraReducedBusiness$OverTime)
tbl
chisq.test(tbl)
#Shows marital status and overtime are highly dependent
tbl <- table(hraReducedBusiness$MaritalStatus, hraReducedBusiness$Department)
tbl
chisq.test(tbl)
#Slightly related
tbl <- table(hraReducedBusiness$BusinessTravel, hraReducedBusiness$MaritalStatus)
tbl
chisq.test(tbl)
#Slight relation
tbl <- table(hraReducedBusiness$OverTime, hraReducedBusiness$Department)
tbl
chisq.test(tbl)
#Highly related
tbl <- table(hraReducedBusiness$BusinessTravel, hraReducedBusiness$OverTime)
tbl
chisq.test(tbl)
#Slightly related
tbl <- table(hraReducedBusiness$Gender, hraReducedBusiness$OverTime)
tbl
chisq.test(tbl)
#Slightly related
tbl <- table(hraReducedBusiness$Gender, hraReducedBusiness$MaritalStatus)
tbl
chisq.test(tbl)
#Slightly Related
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = DistanceFromHome)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = Gender, y = HourlyRate)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = Department, y = Education)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = Age)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = YearsSinceLastPromotion)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = YearsWithCurrManager)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = JobSatisfaction)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
ggplot(mapping = aes(x = BusinessTravel, y = EnvironmentSatisfaction)) +
geom_boxplot() +
theme_bw()
hraReducedBusiness %>%
select(-TotalWorkingYears) ->
hrareducedcor
hra.logit <- glm(hraReducedBusiness$Attrition ~ ., data=hraReducedBusiness, family=binomial(link="logit"))
hra.logit.cor.null <- glm(hrareducedcor$Attrition ~ 1, data=hraReducedBusiness, family=binomial(link="logit"))
hra.logit.cor.full <- glm(hrareducedcor$Attrition ~ ., data=hraReducedBusiness, family=binomial(link="logit"))
hra.step.backward <- step(hra.logit.cor.full, scope=list(lower=hra.logit.cor.null, upper=hra.logit.cor.full), direction="both", test="F")
summary(hra.step.backward)
hrareducedcor %>%
select(Attrition, Age, BusinessTravel, Department, DistanceFromHome, EnvironmentSatisfaction, Gender, JobLevel, JobSatisfaction, MaritalStatus,
OverTime, RelationshipSatisfaction, WorkLifeBalance, YearsSinceLastPromotion, YearsWithCurrManager) ->
hrastepreduced
hra.logit.final.red <- glm(hrastepreduced$Attrition ~ ., data=hrastepreduced, family=binomial(link="logit"))
summary(hra.logit.final.red)
-2*logLik(hra.logit) # 2LL
deviance(hra.logit) # Should yield the same value
AIC(hra.logit) # 2LL + 2*Number of variables
-2*logLik(hra.logit.final.red) # 2LL
deviance(hra.logit.final.red) # Should yield the same value
AIC(hra.logit.final.red) # 2LL + 2*Number of variables
hra.logit <- glm(hraReducedBusiness$Attrition ~ ., data=hraReducedBusiness, family=binomial(link="logit"))
dwtest(hra.logit)
hra.logit.final.red <- glm(hrastepreduced$Attrition ~ ., data=hrastepreduced, family=binomial(link="logit"))
dwtest(hra.logit.final.red)
vif(hra.logit)
vif(hra.logit.final.red)
attach(hraReducedBusiness)
set.seed(1)
train <- sample(1:nrow(hraReducedBusiness), 0.7*nrow(hraReducedBusiness))
test <- seq(1:nrow(hraReducedBusiness))[-train]
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hraReducedBusiness[train,])
# Predicted values using the fitted train model and the test data for HRA Attrition
hra.logit.test=predict(hra.logit.train, hraReducedBusiness, type="response")[test]
#Convert proportions to actual 0's or 1's
hra.pred.test = ifelse(hra.logit.test>0.5, 1,0)
# Cross tabulate Prediction with Actual
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
#Final Confusion Matrix
conf.mat
#We can see that our model does a very good job at predicting No's but is not that good at predicting Yes's
# Computing Fit Statistics
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
# Now let's use these to compute accuracy and error rates
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
# Sensitivity -- rate of correct positives
Sensitivity <- TruP / TotP
#Prediction for true positives is quite bad
# Specificity -- rate of correct negatives
Specificity <- TruN / TotN
#Predicting true negatives is really good with this model.
# False Positive Rate
FalseP.Rate <- 1 - Specificity
logit.rates.50 <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.50) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
print(logit.rates.50, digits=2)
hra.pred.test = ifelse(hra.logit.test>0.2, 1,0)
hra.pred.test[1:10] # List first 10
# Cross tabulate Prediction with Actual
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
#Final Confusion Matrix
conf.mat
#We can see that our model does a very good job at predicting No's but is not that good at predicting Yes's
# Computing Fit Statistics
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
# Now let's use these to compute accuracy and error rates
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
#The overall error rate is quite bad
# Sensitivity -- rate of correct positives
Sensitivity <- TruP / TotP
# Specificity -- rate of correct negatives
Specificity <- TruN / TotN
# False Positive Rate
FalseP.Rate <- 1 - Specificity
logit.rates.20 <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.20) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
logit.fit.stats.compare <- rbind(logit.rates.50, logit.rates.20)
hra.pred.test = ifelse(hra.logit.test>0.30, 1,0)
hra.pred.test[1:10] # List first 10
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
#We can see that our model does a very good job at predicting No's but is not that good at predicting Yes's
# Computing Fit Statistics
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
# Now let's use these to compute accuracy and error rates
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
# Sensitivity -- rate of correct positives
Sensitivity <- TruP / TotP
# Specificity -- rate of correct negatives
Specificity <- TruN / TotN
# False Positive Rate
FalseP.Rate <- 1 - Specificity
logit.rates.30 <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.30) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
print(logit.rates.30, digits=2)
logit.fit.stats.compare.new <- rbind(logit.fit.stats.compare, logit.rates.30)
print(logit.fit.stats.compare.new, digits=2)
#Finally, with Lambda = 0.25
hra.pred.test = ifelse(hra.logit.test>0.275, 1,0)
hra.pred.test[1:10] # List first 10
# Cross tabulate Prediction with Actual
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
#Final Confusion Matrix
conf.mat
#We can see that our model does a very good job at predicting No's but is not that good at predicting Yes's
# Computing Fit Statistics
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
# Now let's use these to compute accuracy and error rates
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
# Sensitivity -- rate of correct positives
Sensitivity <- TruP / TotP
# Specificity -- rate of correct negatives
Specificity <- TruN / TotN
# False Positive Rate
FalseP.Rate <- 1 - Specificity
logit.rates.275 <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.275) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
print(logit.rates.275, digits=2)
logit.fit.stats.compare.new1 <- rbind(logit.fit.stats.compare.new, logit.rates.275)
print("Final Comparision of the four models:")
print(logit.fit.stats.compare.new1, digits=2)
pred <- prediction(hra.logit.test, Attrition[test])
# The next step is to use the performance(){ROCR} function to create the ROC object. Use "tpr" for True Positive Rate in the vertical axis, and "fpr" for False Positive Rate in the horizontal axis. Other possible values are: "acc"=accuracy; "err"=error rate; "sens"=sensitivity; "spec"=specificity; "auc"=area under the curve
perf <- performance(pred,"tpr","fpr")
plot(perf, colorize=T)
# Computing the AUC -- also done with the performance() function:
auc <- performance(pred,"auc")
# The performance() object above stores the name of the variable in @y.name[[1]] and the actual AUC in @y.values[[1]]. Note: the use of double brackets [[]] instead of single brackets [] and @ instead of $ to access values is because the performance() object is a "list" not a data frame. Lists use [[]] for indexing values and @ for accessing elements in the list.
c(auc@y.name[[1]], auc@y.values[[1]])
attach(hrastepreduced)
set.seed(1)
train <- sample(1:nrow(hrastepreduced), 0.7*nrow(hrastepreduced))
test <- seq(1:nrow(hrastepreduced))[-train]
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hrastepreduced[train,])
hra.logit.test=predict(hra.logit.train, hrastepreduced, type="response")[test]
hra.pred.test = ifelse(hra.logit.test>0.5, 1,0)
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
Sensitivity <- TruP / TotP
Specificity <- TruN / TotN
FalseP.Rate <- 1 - Specificity
logit.rates.50.red <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.50.red) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
logit.fit.stats.compare.red <- rbind(logit.rates.50.red, logit.fit.stats.compare.new1)
print(logit.fit.stats.compare.red, digits = 2)
hra.pred.test = ifelse(hra.logit.test>0.2, 1,0)
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
Sensitivity <- TruP / TotP
Specificity <- TruN / TotN
FalseP.Rate <- 1 - Specificity
logit.rates.20.red <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.20.red) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
logit.fit.stats.compare.red <- rbind(logit.rates.50.red, logit.rates.20.red)
hra.pred.test = ifelse(hra.logit.test>0.3, 1,0)
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
Accuracy.Rate <- (TruN + TruP) / Tot
Accuracy.Rate
Error.Rate <- (FalN + FalP) / Tot
Sensitivity <- TruP / TotP
Specificity <- TruN / TotN
FalseP.Rate <- 1 - Specificity
FalseP.Rate
logit.rates.30.red <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.30.red) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
logit.fit.stats.compare.new.red <- rbind(logit.fit.stats.compare.red, logit.rates.30.red)
hra.pred.test = ifelse(hra.logit.test>0.275, 1,0)
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
TruN <- conf.mat[1,1] # True negatives
TruP <- conf.mat[2,2] # True positives
FalN <- conf.mat[1,2] # False negatives
FalP <- conf.mat[2,1] # False positives
TotN <- conf.mat[1,1] + conf.mat[2,1] # Total negatives
TotP <- conf.mat[1,2] + conf.mat[2,2] # Total positives
Tot <- TotN+TotP # Total
Accuracy.Rate <- (TruN + TruP) / Tot
Error.Rate <- (FalN + FalP) / Tot
Sensitivity <- TruP / TotP
Specificity <- TruN / TotN
FalseP.Rate <- 1 - Specificity
logit.rates.275.red <- c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalseP.Rate)
names(logit.rates.275.red) <- c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
logit.fit.stats.compare.new1.red <- rbind(logit.fit.stats.compare.new.red, logit.rates.275.red)
print("Final Comparision of the four models:")
print(logit.fit.stats.compare.new1.red, digits=2)
logit.fit.stats.compare.new1.final <- rbind(logit.fit.stats.compare.new1.red, logit.fit.stats.compare.new1)
print(logit.fit.stats.compare.new1.final, digits = 2)
pred <- prediction(hra.logit.test, Attrition[test])
perf <- performance(pred,"tpr","fpr")
plot(perf, colorize=T)
auc <- performance(pred,"auc")
c(auc@y.name[[1]], auc@y.values[[1]])
hra.tree <- tree(Attrition~., hraReducedBusiness)
summary(hra.tree)
plot(hra.tree)
text(hra.tree, pretty = 0)
hra.tree
hra.tree.step <- tree(Attrition~., hrastepreduced)
summary(hra.tree.step)
plot(hra.tree.step)
text(hra.tree, pretty = 0)
hra.tree.step
hra.tree.step.large <- tree(Attrition~.,hrastepreduced, mindev=0.005)
plot(hra.tree.step.large) # Plot the tree
text(hra.tree.step.large, pretty=0) # Let's make it pretty and add labels
cv.hrareduced <- cv.tree(hra.tree.step.large, FUN = prune.misclass)
cv.hrareduced
cbind("Tree Size"=cv.hrareduced$size, "Misclass"=cv.hrareduced$dev)
plot(cv.hrareduced, type="b")
prune.hrastepred=prune.misclass(hra.tree.step.large,best=13)
summary(prune.hrastepred)
plot(prune.hrastepred) # Plot the tree
text(prune.hrastepred, pretty=0) # With labels
train=sample(1:nrow(hrastepreduced), 0.7*nrow(hrastepreduced))
test=seq(1:nrow(hrastepreduced))[-train]
hra.step.train.tree = tree(Attrition ~ ., data=hrastepreduced[train,])
hra.step.train.tree # See tree results
summary(hra.step.train.tree) # Basic tree results
plot(hra.step.train.tree) # Plot the tree
text(hra.step.train.tree, pretty=0) # Add labels, pretty messy tree
hra.step.test = hrastepreduced[test,]
hra.tree.pred.step = predict(hra.step.train.tree, hra.step.test, type="class")
hra.step.pred.prob=predict(hra.step.train.tree, hra.step.test)
hra.tree.confmat=table("Predicted"=hra.tree.pred.step, "Actual"=hra.step.test$Attrition) # Confusion matrix
hra.tree.confmat
TruN=hra.tree.confmat[1,1] # True negatives
TruP=hra.tree.confmat[2,2] # True positives
FalN=hra.tree.confmat[1,2] # False negatives
FalP=hra.tree.confmat[2,1] # False positives
TotN=hra.tree.confmat[1,1] + hra.tree.confmat[2,1] # Total negatives
TotP=hra.tree.confmat[1,2] + hra.tree.confmat[2,2] # Total positives
Tot=TotN+TotP # Total
Accuracy.Rate=(TruN+TruP)/Tot
Error.Rate=(FalN+FalP)/Tot
Sensitivity=TruP/TotP # Proportion of correct positives
Specificity=TruN/TotN
FalP.Rate = 1 - Specificity
tree.rates.50=c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalP.Rate)
names(tree.rates.50)=c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
hra.tree.pred.class.275 = ifelse(hra.step.pred.prob[,2]>0.275, 1, 0)
hra.tree.confmat.275 <- table(hra.tree.pred.class.275, hra.step.test$Attrition)
hra.tree.confmat.275
TruN=hra.tree.confmat.275[1,1] # True negatives
TruP=hra.tree.confmat.275[2,2] # True positives
FalN=hra.tree.confmat.275[1,2] # False negatives
FalP=hra.tree.confmat.275[2,1] # False positives
TotN=hra.tree.confmat.275[1,1] + hra.tree.confmat.275[2,1] # Total negatives
TotP=hra.tree.confmat.275[1,2] + hra.tree.confmat.275[2,2] # Total positives
Tot=TotN+TotP # Total
Accuracy.Rate=(TruN+TruP)/Tot
Error.Rate=(FalN+FalP)/Tot
Sensitivity=TruP/TotP # Proportion of correct positives
Specificity=TruN/TotN # Proportion of correct negatives
FalP.Rate = 1 - Specificity
tree.rates.275=c(Accuracy.Rate, Error.Rate, Sensitivity, Specificity, FalP.Rate)
names(tree.rates.275)=c("Accuracy Rate", "Error Rate", "Sensitivity", "Specificity", "False Positives")
tree.rates.275
rbind(tree.rates.50, tree.rates.275, logit.fit.stats.compare.new1.final)
pred <- prediction(hra.step.pred.prob[,2], hra.step.test$Attrition)
perf=performance(pred,"tpr","fpr")
plot(perf, colorize=TRUE)
auc=performance(pred,"auc") # Compute the AUC
c(auc@y.name[[1]], auc@y.values[[1]]) # Display the AUC
attach(hrastepreduced)
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hrastepreduced)
set.seed(1)
test <- sample(1:nrow(hrastepreduced), 0.2*nrow(hrastepreduced))
hra.logit.test=predict(hra.logit.train, hrastepreduced, type="response")[test]
hra.pred.test = ifelse(hra.logit.test>0.5, 1,0)
conf.mat <- table("Predicted"=hra.pred.test, "Actual"=Attrition[test])
colnames(conf.mat) <- c("No", "Yes")
rownames(conf.mat) <- c("No", "Yes")
conf.mat
hra.logit.test
hra.pred.test = ifelse(hra.logit.test>0.275, 1,0)
sum(hra.pred.test)
hrastepreduced
finalProportion <- Sum/294
Sum <- sum(hra.pred.test)
finalProportion <- Sum/294
finalProportion
hra.pred.test = ifelse(hra.logit.test>0.5, 1,0)
Sum <- sum(hra.pred.test)
hrastepreduced
finalProportion <- Sum/294
finalProportion
print("Final porion of employees leaving: " finalProportion)
print("Final porion of employees leaving: ", finalProportion)
finalProportion <- Sum/294
finalProportion
print("Final porion of employees leaving: ")
finalProportion
attach(hrastepreduced)
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hrastepreduced)
set.seed(1)
test <- sample(1:nrow(hrastepreduced), 0.2*nrow(hrastepreduced))
hra.logit.test=predict(hra.logit.train, hrastepreduced, type="response")[test]
hra.logit.test
attach(hrastepreduced)
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hrastepreduced)
set.seed(1)
test <- sample(1:nrow(hrastepreduced), 0.2*nrow(hrastepreduced))
hra.logit.test=predict(hra.logit.train, hrastepreduced, type="response")[test]
hra.pred.test = ifelse(hra.logit.test>0.275, 1,0)
Sum <- sum(hra.pred.test)
finalProportion <- Sum/294
finalProportion
print("Final porion of employees leaving: ")
finalProportion
finalProportion <- (Sum/294) * 100
print("Final porion of employees leaving: ")
finalProportion
attach(hrastepreduced)
hra.logit.train <- glm(Attrition ~ ., family=binomial(link="logit"), data=hrastepreduced)
set.seed(1)
test <- sample(1:nrow(hrastepreduced), 0.2*nrow(hrastepreduced))
hra.logit.test=predict(hra.logit.train, hrastepreduced, type="response")[test]
hra.pred.test = ifelse(hra.logit.test>0.275, 1,0)
Sum <- sum(hra.pred.test)
finalProportion <- (Sum/294) * 100
print("Final porion of employees leaving: ")
finalProportion
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
HRA <- read.csv(file = "..\\HR-Employee-Attrition.csv", header = TRUE, sep = ",")
HRA <- read.csv(file = "..\\Data\\HR-Employee-Attrition.csv", header = TRUE, sep = ",")
knitr::opts_chunk$set(echo = TRUE)
HRA <- read.csv(file = "..\\Data\\HR-Employee-Attrition.csv", header = TRUE, sep = ",")
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ROCR))
suppressPackageStartupMessages(library(Hmisc))
suppressPackageStartupMessages(library(corrplot))
suppressPackageStartupMessages(library(lmtest))
suppressPackageStartupMessages(library(perturb))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(randomForest))
suppressPackageStartupMessages(library(tree))
HRA <- read.csv(file = "..\\Data\\HR-Employee-Attrition.csv", header = TRUE, sep = ",")
head(HRA)
str(HRA)
names(HRA)
#Renaming Age column to "Age"
colnames(HRA)[1] <- "Age"
HRA %>%
ggplot(HRA, mapping = aes(x = Age, fill = Attrition)) +
geom_histogram() +
theme_bw() +
xlab("AGE") +
ylab("Number of Employees")
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(ROCR))
suppressPackageStartupMessages(library(Hmisc))
suppressPackageStartupMessages(library(corrplot))
suppressPackageStartupMessages(library(lmtest))
suppressPackageStartupMessages(library(perturb))
suppressPackageStartupMessages(library(car))
suppressPackageStartupMessages(library(randomForest))
suppressPackageStartupMessages(library(tree))
HRA <- read.csv(file = "..\\Data\\HR-Employee-Attrition.csv", header = TRUE, sep = ",")
head(HRA)
str(HRA)
names(HRA)
#Renaming Age column to "Age"
colnames(HRA)[1] <- "Age"
HRA %>%
ggplot(HRA, mapping = aes(x = Age, fill = Attrition)) +
geom_histogram() +
theme_bw() +
xlab("AGE") +
ylab("Number of Employees")
setwd("C:/Projects'/Optimus/The Project/codeMarkdown")
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
voter <- read.csv("..\\Data\\voterfile.csv")
knitr::opts_chunk$set(echo = TRUE)
voter <- read.csv("..\\Data\\voterfile.csv")
